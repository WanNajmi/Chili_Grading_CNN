{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import preprocessing\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Activation,BatchNormalization, Dropout\n",
    "from tensorflow.keras import Sequential\n",
    "from keras.optimizers import *\n",
    "\"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import PIL\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 426 files belonging to 6 classes.\n",
      "Using 384 files for training.\n"
     ]
    }
   ],
   "source": [
    "#load train images\n",
    "img_size=160\n",
    "train_dataset = tf.keras.utils.image_dataset_from_directory('C:/Users/User/Documents/UPM/Semester 3/Category/basedata',\n",
    "                                                            validation_split=0.1,\n",
    "                                                            batch_size = 32,\n",
    "                                                            label_mode = 'categorical',\n",
    "                                                            subset='training',\n",
    "                                                            seed=123,\n",
    "                                                            image_size=(img_size,img_size),\n",
    "                                                            shuffle=True\n",
    "                                                           )\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 426 files belonging to 6 classes.\n",
      "Using 42 files for validation.\n"
     ]
    }
   ],
   "source": [
    "#load test images\n",
    "img_size=160\n",
    "test_dataset = tf.keras.utils.image_dataset_from_directory('C:/Users/User/Desktop/Category/basedata/',\n",
    "                                                           validation_split=0.1,\n",
    "                                                           batch_size = 32,\n",
    "                                                           label_mode = 'categorical',\n",
    "                                                           subset='validation',\n",
    "                                                           seed=123,\n",
    "                                                           image_size=(img_size,img_size),\n",
    "                                                           shuffle=True\n",
    "                                                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_layer = tf.keras.layers.Rescaling(1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 150, 150, 64)      23296     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 75, 75, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 75, 75, 64)       256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 65, 65, 128)       991360    \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 32, 32, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 32, 32, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 22, 22, 256)       3965184   \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 11, 11, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 11, 11, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " global_max_pooling2d (Globa  (None, 256)              0         \n",
      " lMaxPooling2D)                                                  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               65792     \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 6)                 1542      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,049,990\n",
      "Trainable params: 5,048,582\n",
      "Non-trainable params: 1,408\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "img_size=160\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "# Input layer\n",
    "# Can be omitted, you can specify the input_shape in other layers\n",
    "model.add(tf.keras.layers.InputLayer(input_shape=(img_size,img_size,3)))\n",
    "\n",
    "# 1st 2D Convolution layer\n",
    "model.add(tf.keras.layers.Conv2D(64, kernel_size=(11,11), activation='relu'))\n",
    "# Max Pool layer \n",
    "# It downsmaples the input representetion within the pool_size size\n",
    "model.add(tf.keras.layers.MaxPool2D())\n",
    "# Normalization layer\n",
    "# The layer normalizes its output using the mean and standard deviation of the current batch of inputs.\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "\n",
    "# 2nd 2D Convolution layer\n",
    "model.add(tf.keras.layers.Conv2D(128, kernel_size=(11,11),activation='relu'))\n",
    "# Max Pool layer \n",
    "model.add(tf.keras.layers.MaxPool2D())\n",
    "# Normalization layer\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "# 1st fully convolutional layer \n",
    "model.add(tf.keras.layers.Conv2D(256, kernel_size=(11,11),activation='relu'))\n",
    "# Max Pool layer \n",
    "model.add(tf.keras.layers.MaxPool2D())\n",
    "# Normalization layer\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "# Global Max Pool layer\n",
    "model.add(tf.keras.layers.GlobalMaxPool2D())\n",
    "\n",
    "\n",
    "# Dense Layers after flattening the data\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "\n",
    "# Normalization layer\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "#Add Output Layer\n",
    "model.add(tf.keras.layers.Dense(6, activation='softmax')) # = 12 predicted classes\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "#custom_early_stopping = EarlyStopping(\n",
    "#    monitor='val_accuracy', \n",
    "#    patience=20, \n",
    "#    min_delta=0.001, \n",
    "#    mode='max'\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/270\n",
      "12/12 [==============================] - 14s 598ms/step - loss: 1.5096 - accuracy: 0.4167 - val_loss: 773.7886 - val_accuracy: 0.1667\n",
      "Epoch 2/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 0.8339 - accuracy: 0.6849 - val_loss: 503.7129 - val_accuracy: 0.1667\n",
      "Epoch 3/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 0.6122 - accuracy: 0.7552 - val_loss: 298.4139 - val_accuracy: 0.1667\n",
      "Epoch 4/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 0.5316 - accuracy: 0.7995 - val_loss: 200.2665 - val_accuracy: 0.1667\n",
      "Epoch 5/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 0.4201 - accuracy: 0.8281 - val_loss: 123.7760 - val_accuracy: 0.1667\n",
      "Epoch 6/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 0.3367 - accuracy: 0.8698 - val_loss: 84.3863 - val_accuracy: 0.1667\n",
      "Epoch 7/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 0.3056 - accuracy: 0.8932 - val_loss: 72.8834 - val_accuracy: 0.1667\n",
      "Epoch 8/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 0.2784 - accuracy: 0.8932 - val_loss: 40.2053 - val_accuracy: 0.1667\n",
      "Epoch 9/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 0.2538 - accuracy: 0.9141 - val_loss: 47.9359 - val_accuracy: 0.1667\n",
      "Epoch 10/270\n",
      "12/12 [==============================] - 2s 191ms/step - loss: 0.2141 - accuracy: 0.9375 - val_loss: 40.2161 - val_accuracy: 0.1667\n",
      "Epoch 11/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 0.2040 - accuracy: 0.9349 - val_loss: 24.1505 - val_accuracy: 0.1667\n",
      "Epoch 12/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 0.2144 - accuracy: 0.9245 - val_loss: 25.6720 - val_accuracy: 0.1667\n",
      "Epoch 13/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 0.1934 - accuracy: 0.9349 - val_loss: 23.0235 - val_accuracy: 0.1667\n",
      "Epoch 14/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 0.1406 - accuracy: 0.9557 - val_loss: 17.9324 - val_accuracy: 0.1667\n",
      "Epoch 15/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 0.2065 - accuracy: 0.9245 - val_loss: 11.0465 - val_accuracy: 0.2143\n",
      "Epoch 16/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 0.1409 - accuracy: 0.9583 - val_loss: 8.6754 - val_accuracy: 0.3571\n",
      "Epoch 17/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 0.1254 - accuracy: 0.9688 - val_loss: 7.1809 - val_accuracy: 0.5238\n",
      "Epoch 18/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 0.0750 - accuracy: 0.9870 - val_loss: 10.1563 - val_accuracy: 0.4286\n",
      "Epoch 19/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 0.0453 - accuracy: 0.9922 - val_loss: 9.8062 - val_accuracy: 0.4762\n",
      "Epoch 20/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 0.0411 - accuracy: 0.9922 - val_loss: 7.1466 - val_accuracy: 0.5238\n",
      "Epoch 21/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 0.0290 - accuracy: 0.9974 - val_loss: 4.9210 - val_accuracy: 0.5476\n",
      "Epoch 22/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 0.0235 - accuracy: 0.9974 - val_loss: 2.9544 - val_accuracy: 0.5714\n",
      "Epoch 23/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 0.0247 - accuracy: 0.9948 - val_loss: 4.0972 - val_accuracy: 0.5476\n",
      "Epoch 24/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 0.0236 - accuracy: 0.9974 - val_loss: 4.1309 - val_accuracy: 0.5476\n",
      "Epoch 25/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 0.0167 - accuracy: 0.9974 - val_loss: 1.8096 - val_accuracy: 0.5714\n",
      "Epoch 26/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 0.0159 - accuracy: 0.9974 - val_loss: 1.7513 - val_accuracy: 0.6429\n",
      "Epoch 27/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 1.0214 - val_accuracy: 0.7619\n",
      "Epoch 28/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.7921 - val_accuracy: 0.7857\n",
      "Epoch 29/270\n",
      "12/12 [==============================] - 2s 191ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.8051 - val_accuracy: 0.7381\n",
      "Epoch 30/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.7821 - val_accuracy: 0.7619\n",
      "Epoch 31/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.7722 - val_accuracy: 0.7619\n",
      "Epoch 32/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.7439 - val_accuracy: 0.7381\n",
      "Epoch 33/270\n",
      "12/12 [==============================] - 2s 191ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.7871 - val_accuracy: 0.7143\n",
      "Epoch 34/270\n",
      "12/12 [==============================] - 2s 191ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.7598 - val_accuracy: 0.7619\n",
      "Epoch 35/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.7460 - val_accuracy: 0.7619\n",
      "Epoch 36/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.7609 - val_accuracy: 0.7857\n",
      "Epoch 37/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.8810 - val_accuracy: 0.7619\n",
      "Epoch 38/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.8220 - val_accuracy: 0.7857\n",
      "Epoch 39/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8022 - val_accuracy: 0.7857\n",
      "Epoch 40/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.7860 - val_accuracy: 0.7857\n",
      "Epoch 41/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.8087 - val_accuracy: 0.7857\n",
      "Epoch 42/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.8441 - val_accuracy: 0.7857\n",
      "Epoch 43/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8527 - val_accuracy: 0.7857\n",
      "Epoch 44/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8614 - val_accuracy: 0.7857\n",
      "Epoch 45/270\n",
      "12/12 [==============================] - 2s 188ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8629 - val_accuracy: 0.7857\n",
      "Epoch 46/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.8761 - val_accuracy: 0.8095\n",
      "Epoch 47/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.9032 - val_accuracy: 0.7857\n",
      "Epoch 48/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.9007 - val_accuracy: 0.7381\n",
      "Epoch 49/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.8883 - val_accuracy: 0.7857\n",
      "Epoch 50/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.8745 - val_accuracy: 0.7857\n",
      "Epoch 51/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.9030 - val_accuracy: 0.7619\n",
      "Epoch 52/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.9118 - val_accuracy: 0.7857\n",
      "Epoch 53/270\n",
      "12/12 [==============================] - 2s 191ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.9163 - val_accuracy: 0.7857\n",
      "Epoch 54/270\n",
      "12/12 [==============================] - 2s 191ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.9536 - val_accuracy: 0.7619\n",
      "Epoch 55/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 7.6565e-04 - accuracy: 1.0000 - val_loss: 0.9411 - val_accuracy: 0.7619\n",
      "Epoch 56/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.9375 - val_accuracy: 0.7857\n",
      "Epoch 57/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 8.1700e-04 - accuracy: 1.0000 - val_loss: 0.9284 - val_accuracy: 0.7857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.9310 - val_accuracy: 0.7857\n",
      "Epoch 59/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.9376 - val_accuracy: 0.7857\n",
      "Epoch 60/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.9363 - val_accuracy: 0.7857\n",
      "Epoch 61/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 7.0695e-04 - accuracy: 1.0000 - val_loss: 0.9456 - val_accuracy: 0.7857\n",
      "Epoch 62/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.9230 - val_accuracy: 0.7857\n",
      "Epoch 63/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 5.8905e-04 - accuracy: 1.0000 - val_loss: 0.9182 - val_accuracy: 0.7857\n",
      "Epoch 64/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 7.8479e-04 - accuracy: 1.0000 - val_loss: 0.9206 - val_accuracy: 0.7857\n",
      "Epoch 65/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 7.9310e-04 - accuracy: 1.0000 - val_loss: 0.9289 - val_accuracy: 0.7857\n",
      "Epoch 66/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 7.9576e-04 - accuracy: 1.0000 - val_loss: 0.9242 - val_accuracy: 0.7857\n",
      "Epoch 67/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 9.1538e-04 - accuracy: 1.0000 - val_loss: 0.9291 - val_accuracy: 0.7857\n",
      "Epoch 68/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 7.6976e-04 - accuracy: 1.0000 - val_loss: 0.9252 - val_accuracy: 0.7857\n",
      "Epoch 69/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 9.6713e-04 - accuracy: 1.0000 - val_loss: 0.9641 - val_accuracy: 0.7857\n",
      "Epoch 70/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 6.3416e-04 - accuracy: 1.0000 - val_loss: 0.9295 - val_accuracy: 0.7619\n",
      "Epoch 71/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 6.4320e-04 - accuracy: 1.0000 - val_loss: 0.9310 - val_accuracy: 0.7857\n",
      "Epoch 72/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 7.4901e-04 - accuracy: 1.0000 - val_loss: 0.9634 - val_accuracy: 0.7857\n",
      "Epoch 73/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.0084 - val_accuracy: 0.7857\n",
      "Epoch 74/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 5.6568e-04 - accuracy: 1.0000 - val_loss: 0.9884 - val_accuracy: 0.7857\n",
      "Epoch 75/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 4.4472e-04 - accuracy: 1.0000 - val_loss: 0.9371 - val_accuracy: 0.8095\n",
      "Epoch 76/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 5.7307e-04 - accuracy: 1.0000 - val_loss: 0.9297 - val_accuracy: 0.7857\n",
      "Epoch 77/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 5.5574e-04 - accuracy: 1.0000 - val_loss: 0.9288 - val_accuracy: 0.7857\n",
      "Epoch 78/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 5.4767e-04 - accuracy: 1.0000 - val_loss: 0.9509 - val_accuracy: 0.7857\n",
      "Epoch 79/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 6.4285e-04 - accuracy: 1.0000 - val_loss: 0.9537 - val_accuracy: 0.7619\n",
      "Epoch 80/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 5.7074e-04 - accuracy: 1.0000 - val_loss: 0.9603 - val_accuracy: 0.7619\n",
      "Epoch 81/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 6.8624e-04 - accuracy: 1.0000 - val_loss: 1.0222 - val_accuracy: 0.7619\n",
      "Epoch 82/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 4.8267e-04 - accuracy: 1.0000 - val_loss: 1.0409 - val_accuracy: 0.7619\n",
      "Epoch 83/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 4.6626e-04 - accuracy: 1.0000 - val_loss: 0.9730 - val_accuracy: 0.7619\n",
      "Epoch 84/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 4.1725e-04 - accuracy: 1.0000 - val_loss: 0.9651 - val_accuracy: 0.7619\n",
      "Epoch 85/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 3.2502e-04 - accuracy: 1.0000 - val_loss: 0.9642 - val_accuracy: 0.7619\n",
      "Epoch 86/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 4.6397e-04 - accuracy: 1.0000 - val_loss: 0.9641 - val_accuracy: 0.7857\n",
      "Epoch 87/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 4.4394e-04 - accuracy: 1.0000 - val_loss: 0.9734 - val_accuracy: 0.7619\n",
      "Epoch 88/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 5.2656e-04 - accuracy: 1.0000 - val_loss: 0.9770 - val_accuracy: 0.7619\n",
      "Epoch 89/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 4.8656e-04 - accuracy: 1.0000 - val_loss: 0.9684 - val_accuracy: 0.7619\n",
      "Epoch 90/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 6.4533e-04 - accuracy: 1.0000 - val_loss: 0.9648 - val_accuracy: 0.7619\n",
      "Epoch 91/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 3.7679e-04 - accuracy: 1.0000 - val_loss: 0.9750 - val_accuracy: 0.7857\n",
      "Epoch 92/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 5.6687e-04 - accuracy: 1.0000 - val_loss: 0.9660 - val_accuracy: 0.7857\n",
      "Epoch 93/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 4.1101e-04 - accuracy: 1.0000 - val_loss: 0.9714 - val_accuracy: 0.7619\n",
      "Epoch 94/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 4.1174e-04 - accuracy: 1.0000 - val_loss: 0.9780 - val_accuracy: 0.7857\n",
      "Epoch 95/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 4.0195e-04 - accuracy: 1.0000 - val_loss: 1.0016 - val_accuracy: 0.7857\n",
      "Epoch 96/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 3.6770e-04 - accuracy: 1.0000 - val_loss: 0.9800 - val_accuracy: 0.7857\n",
      "Epoch 97/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 3.2312e-04 - accuracy: 1.0000 - val_loss: 0.9709 - val_accuracy: 0.7857\n",
      "Epoch 98/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 4.2007e-04 - accuracy: 1.0000 - val_loss: 0.9919 - val_accuracy: 0.7857\n",
      "Epoch 99/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 3.9831e-04 - accuracy: 1.0000 - val_loss: 0.9962 - val_accuracy: 0.7857\n",
      "Epoch 100/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 2.9677e-04 - accuracy: 1.0000 - val_loss: 1.0223 - val_accuracy: 0.7857\n",
      "Epoch 101/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 4.2776e-04 - accuracy: 1.0000 - val_loss: 1.0392 - val_accuracy: 0.8095\n",
      "Epoch 102/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 2.9495e-04 - accuracy: 1.0000 - val_loss: 1.0180 - val_accuracy: 0.7857\n",
      "Epoch 103/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 2.6349e-04 - accuracy: 1.0000 - val_loss: 0.9988 - val_accuracy: 0.7857\n",
      "Epoch 104/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 3.8503e-04 - accuracy: 1.0000 - val_loss: 0.9936 - val_accuracy: 0.7857\n",
      "Epoch 105/270\n",
      "12/12 [==============================] - 2s 191ms/step - loss: 4.5996e-04 - accuracy: 1.0000 - val_loss: 0.9780 - val_accuracy: 0.8095\n",
      "Epoch 106/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 2.7025e-04 - accuracy: 1.0000 - val_loss: 0.9862 - val_accuracy: 0.8095\n",
      "Epoch 107/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 2.6480e-04 - accuracy: 1.0000 - val_loss: 0.9955 - val_accuracy: 0.8095\n",
      "Epoch 108/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 3.1561e-04 - accuracy: 1.0000 - val_loss: 1.0083 - val_accuracy: 0.8333\n",
      "Epoch 109/270\n",
      "12/12 [==============================] - 2s 191ms/step - loss: 1.8093e-04 - accuracy: 1.0000 - val_loss: 1.0085 - val_accuracy: 0.8095\n",
      "Epoch 110/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 2.8246e-04 - accuracy: 1.0000 - val_loss: 0.9951 - val_accuracy: 0.8095\n",
      "Epoch 111/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 2.3334e-04 - accuracy: 1.0000 - val_loss: 1.0005 - val_accuracy: 0.8095\n",
      "Epoch 112/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 2.8558e-04 - accuracy: 1.0000 - val_loss: 1.0025 - val_accuracy: 0.8095\n",
      "Epoch 113/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 3.8513e-04 - accuracy: 1.0000 - val_loss: 1.0269 - val_accuracy: 0.8095\n",
      "Epoch 114/270\n",
      "12/12 [==============================] - 2s 188ms/step - loss: 2.5328e-04 - accuracy: 1.0000 - val_loss: 1.0195 - val_accuracy: 0.8095\n",
      "Epoch 115/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 2.1942e-04 - accuracy: 1.0000 - val_loss: 1.0054 - val_accuracy: 0.8095\n",
      "Epoch 116/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 2.3090e-04 - accuracy: 1.0000 - val_loss: 0.9973 - val_accuracy: 0.8095\n",
      "Epoch 117/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 5.0733e-04 - accuracy: 1.0000 - val_loss: 0.9956 - val_accuracy: 0.7619\n",
      "Epoch 118/270\n",
      "12/12 [==============================] - 2s 188ms/step - loss: 3.9756e-04 - accuracy: 1.0000 - val_loss: 0.9843 - val_accuracy: 0.8095\n",
      "Epoch 119/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 3.1968e-04 - accuracy: 1.0000 - val_loss: 0.9785 - val_accuracy: 0.7857\n",
      "Epoch 120/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 2.3479e-04 - accuracy: 1.0000 - val_loss: 0.9893 - val_accuracy: 0.7857\n",
      "Epoch 121/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 2.7362e-04 - accuracy: 1.0000 - val_loss: 1.0056 - val_accuracy: 0.7857\n",
      "Epoch 122/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 2.9926e-04 - accuracy: 1.0000 - val_loss: 1.0235 - val_accuracy: 0.7857\n",
      "Epoch 123/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 2.1286e-04 - accuracy: 1.0000 - val_loss: 1.0347 - val_accuracy: 0.8095\n",
      "Epoch 124/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 2.4519e-04 - accuracy: 1.0000 - val_loss: 1.0198 - val_accuracy: 0.7857\n",
      "Epoch 125/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 2.9706e-04 - accuracy: 1.0000 - val_loss: 1.0256 - val_accuracy: 0.7857\n",
      "Epoch 126/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 3.7216e-04 - accuracy: 1.0000 - val_loss: 1.0368 - val_accuracy: 0.7857\n",
      "Epoch 127/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 2.7278e-04 - accuracy: 1.0000 - val_loss: 1.0515 - val_accuracy: 0.7857\n",
      "Epoch 128/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 2.6178e-04 - accuracy: 1.0000 - val_loss: 1.0562 - val_accuracy: 0.7857\n",
      "Epoch 129/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 1.8841e-04 - accuracy: 1.0000 - val_loss: 1.0229 - val_accuracy: 0.7857\n",
      "Epoch 130/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 2.7389e-04 - accuracy: 1.0000 - val_loss: 1.0130 - val_accuracy: 0.8095\n",
      "Epoch 131/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 4.5895e-04 - accuracy: 1.0000 - val_loss: 1.1008 - val_accuracy: 0.7857\n",
      "Epoch 132/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 3.1765e-04 - accuracy: 1.0000 - val_loss: 1.0469 - val_accuracy: 0.7857\n",
      "Epoch 133/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 2.2379e-04 - accuracy: 1.0000 - val_loss: 1.0039 - val_accuracy: 0.7619\n",
      "Epoch 134/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 1.6775e-04 - accuracy: 1.0000 - val_loss: 0.9788 - val_accuracy: 0.7857\n",
      "Epoch 135/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 2.6419e-04 - accuracy: 1.0000 - val_loss: 1.0135 - val_accuracy: 0.7857\n",
      "Epoch 136/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 1.3461e-04 - accuracy: 1.0000 - val_loss: 1.0208 - val_accuracy: 0.7857\n",
      "Epoch 137/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 1.8916e-04 - accuracy: 1.0000 - val_loss: 1.0187 - val_accuracy: 0.7857\n",
      "Epoch 138/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 2.0131e-04 - accuracy: 1.0000 - val_loss: 1.0247 - val_accuracy: 0.7857\n",
      "Epoch 139/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 1.9187e-04 - accuracy: 1.0000 - val_loss: 1.0440 - val_accuracy: 0.7857\n",
      "Epoch 140/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 2.9939e-04 - accuracy: 1.0000 - val_loss: 1.0392 - val_accuracy: 0.7857\n",
      "Epoch 141/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 1.6667e-04 - accuracy: 1.0000 - val_loss: 1.0359 - val_accuracy: 0.7857\n",
      "Epoch 142/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 1.0243e-04 - accuracy: 1.0000 - val_loss: 1.0553 - val_accuracy: 0.7857\n",
      "Epoch 143/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 2.2193e-04 - accuracy: 1.0000 - val_loss: 1.0503 - val_accuracy: 0.7857\n",
      "Epoch 144/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 1.5297e-04 - accuracy: 1.0000 - val_loss: 1.0486 - val_accuracy: 0.7857\n",
      "Epoch 145/270\n",
      "12/12 [==============================] - 2s 188ms/step - loss: 1.8438e-04 - accuracy: 1.0000 - val_loss: 1.0411 - val_accuracy: 0.7857\n",
      "Epoch 146/270\n",
      "12/12 [==============================] - 2s 188ms/step - loss: 1.8444e-04 - accuracy: 1.0000 - val_loss: 1.0463 - val_accuracy: 0.8095\n",
      "Epoch 147/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 2.0378e-04 - accuracy: 1.0000 - val_loss: 1.0543 - val_accuracy: 0.8095\n",
      "Epoch 148/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 1.8296e-04 - accuracy: 1.0000 - val_loss: 1.0459 - val_accuracy: 0.8095\n",
      "Epoch 149/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 2.0971e-04 - accuracy: 1.0000 - val_loss: 1.0580 - val_accuracy: 0.7857\n",
      "Epoch 150/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 1.9719e-04 - accuracy: 1.0000 - val_loss: 1.0420 - val_accuracy: 0.8095\n",
      "Epoch 151/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 2.4727e-04 - accuracy: 1.0000 - val_loss: 1.0713 - val_accuracy: 0.8095\n",
      "Epoch 152/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 1.9843e-04 - accuracy: 1.0000 - val_loss: 1.0764 - val_accuracy: 0.8095\n",
      "Epoch 153/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 1.4389e-04 - accuracy: 1.0000 - val_loss: 1.0638 - val_accuracy: 0.8095\n",
      "Epoch 154/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 1.5068e-04 - accuracy: 1.0000 - val_loss: 1.0554 - val_accuracy: 0.8095\n",
      "Epoch 155/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 1.1109e-04 - accuracy: 1.0000 - val_loss: 1.0491 - val_accuracy: 0.8095\n",
      "Epoch 156/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 1.4111e-04 - accuracy: 1.0000 - val_loss: 1.0520 - val_accuracy: 0.8333\n",
      "Epoch 157/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 1.4121e-04 - accuracy: 1.0000 - val_loss: 1.0525 - val_accuracy: 0.8095\n",
      "Epoch 158/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 4.3655e-04 - accuracy: 1.0000 - val_loss: 1.0293 - val_accuracy: 0.8095\n",
      "Epoch 159/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 4.3811e-04 - accuracy: 1.0000 - val_loss: 1.2267 - val_accuracy: 0.7619\n",
      "Epoch 160/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 1.8738e-04 - accuracy: 1.0000 - val_loss: 1.2749 - val_accuracy: 0.7619\n",
      "Epoch 161/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 1.8396e-04 - accuracy: 1.0000 - val_loss: 1.1209 - val_accuracy: 0.7857\n",
      "Epoch 162/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 1.5268e-04 - accuracy: 1.0000 - val_loss: 1.0488 - val_accuracy: 0.7857\n",
      "Epoch 163/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 2.0677e-04 - accuracy: 1.0000 - val_loss: 1.0359 - val_accuracy: 0.7857\n",
      "Epoch 164/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 1.9724e-04 - accuracy: 1.0000 - val_loss: 1.0610 - val_accuracy: 0.7857\n",
      "Epoch 165/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 1.5500e-04 - accuracy: 1.0000 - val_loss: 1.0802 - val_accuracy: 0.8095\n",
      "Epoch 166/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 2.2005e-04 - accuracy: 1.0000 - val_loss: 1.0727 - val_accuracy: 0.7857\n",
      "Epoch 167/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 1.4619e-04 - accuracy: 1.0000 - val_loss: 1.0582 - val_accuracy: 0.7857\n",
      "Epoch 168/270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 2s 189ms/step - loss: 1.1999e-04 - accuracy: 1.0000 - val_loss: 1.0373 - val_accuracy: 0.7857\n",
      "Epoch 169/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 1.2132e-04 - accuracy: 1.0000 - val_loss: 1.0185 - val_accuracy: 0.7857\n",
      "Epoch 170/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 1.3020e-04 - accuracy: 1.0000 - val_loss: 1.0086 - val_accuracy: 0.7857\n",
      "Epoch 171/270\n",
      "12/12 [==============================] - 2s 191ms/step - loss: 2.6693e-04 - accuracy: 1.0000 - val_loss: 1.0844 - val_accuracy: 0.7619\n",
      "Epoch 172/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 1.5534e-04 - accuracy: 1.0000 - val_loss: 1.1041 - val_accuracy: 0.7857\n",
      "Epoch 173/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 4.2286e-04 - accuracy: 1.0000 - val_loss: 1.0988 - val_accuracy: 0.7857\n",
      "Epoch 174/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 1.5622e-04 - accuracy: 1.0000 - val_loss: 1.1049 - val_accuracy: 0.7619\n",
      "Epoch 175/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 2.1678e-04 - accuracy: 1.0000 - val_loss: 1.0191 - val_accuracy: 0.8095\n",
      "Epoch 176/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 1.0243e-04 - accuracy: 1.0000 - val_loss: 1.0177 - val_accuracy: 0.7857\n",
      "Epoch 177/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 1.1491e-04 - accuracy: 1.0000 - val_loss: 1.0401 - val_accuracy: 0.7857\n",
      "Epoch 178/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 1.1800e-04 - accuracy: 1.0000 - val_loss: 1.0548 - val_accuracy: 0.7857\n",
      "Epoch 179/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 9.1622e-05 - accuracy: 1.0000 - val_loss: 1.0656 - val_accuracy: 0.7857\n",
      "Epoch 180/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 1.0805e-04 - accuracy: 1.0000 - val_loss: 1.0720 - val_accuracy: 0.7857\n",
      "Epoch 181/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 1.6492e-04 - accuracy: 1.0000 - val_loss: 1.1060 - val_accuracy: 0.7857\n",
      "Epoch 182/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 9.1142e-05 - accuracy: 1.0000 - val_loss: 1.1092 - val_accuracy: 0.7857\n",
      "Epoch 183/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 8.2763e-05 - accuracy: 1.0000 - val_loss: 1.0843 - val_accuracy: 0.7857\n",
      "Epoch 184/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 1.3481e-04 - accuracy: 1.0000 - val_loss: 1.0668 - val_accuracy: 0.7857\n",
      "Epoch 185/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 1.3447e-04 - accuracy: 1.0000 - val_loss: 1.0455 - val_accuracy: 0.7857\n",
      "Epoch 186/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 1.5512e-04 - accuracy: 1.0000 - val_loss: 1.0411 - val_accuracy: 0.8095\n",
      "Epoch 187/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 1.5558e-04 - accuracy: 1.0000 - val_loss: 1.0258 - val_accuracy: 0.8095\n",
      "Epoch 188/270\n",
      "12/12 [==============================] - 2s 191ms/step - loss: 1.1508e-04 - accuracy: 1.0000 - val_loss: 1.0221 - val_accuracy: 0.8095\n",
      "Epoch 189/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 9.0696e-05 - accuracy: 1.0000 - val_loss: 1.0172 - val_accuracy: 0.8333\n",
      "Epoch 190/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 1.0253e-04 - accuracy: 1.0000 - val_loss: 1.0327 - val_accuracy: 0.8333\n",
      "Epoch 191/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 1.3251e-04 - accuracy: 1.0000 - val_loss: 1.0390 - val_accuracy: 0.7857\n",
      "Epoch 192/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 1.8163e-04 - accuracy: 1.0000 - val_loss: 1.0358 - val_accuracy: 0.8095\n",
      "Epoch 193/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 1.0502e-04 - accuracy: 1.0000 - val_loss: 1.0075 - val_accuracy: 0.8095\n",
      "Epoch 194/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 1.2122e-04 - accuracy: 1.0000 - val_loss: 1.0358 - val_accuracy: 0.8095\n",
      "Epoch 195/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 9.8601e-05 - accuracy: 1.0000 - val_loss: 1.1163 - val_accuracy: 0.8095\n",
      "Epoch 196/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 7.3982e-05 - accuracy: 1.0000 - val_loss: 1.1331 - val_accuracy: 0.8095\n",
      "Epoch 197/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 6.4525e-05 - accuracy: 1.0000 - val_loss: 1.1186 - val_accuracy: 0.8095\n",
      "Epoch 198/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 6.9598e-05 - accuracy: 1.0000 - val_loss: 1.1011 - val_accuracy: 0.8095\n",
      "Epoch 199/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 6.8658e-05 - accuracy: 1.0000 - val_loss: 1.0900 - val_accuracy: 0.8095\n",
      "Epoch 200/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 1.5394e-04 - accuracy: 1.0000 - val_loss: 1.0665 - val_accuracy: 0.7857\n",
      "Epoch 201/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 8.2856e-05 - accuracy: 1.0000 - val_loss: 1.0602 - val_accuracy: 0.7857\n",
      "Epoch 202/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 1.2952e-04 - accuracy: 1.0000 - val_loss: 1.0690 - val_accuracy: 0.7857\n",
      "Epoch 203/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 9.5468e-05 - accuracy: 1.0000 - val_loss: 1.0908 - val_accuracy: 0.7857\n",
      "Epoch 204/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 9.5308e-05 - accuracy: 1.0000 - val_loss: 1.1144 - val_accuracy: 0.7857\n",
      "Epoch 205/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 6.1098e-05 - accuracy: 1.0000 - val_loss: 1.1143 - val_accuracy: 0.7857\n",
      "Epoch 206/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 1.5720e-04 - accuracy: 1.0000 - val_loss: 1.1100 - val_accuracy: 0.7857\n",
      "Epoch 207/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 1.3530e-04 - accuracy: 1.0000 - val_loss: 1.0640 - val_accuracy: 0.7857\n",
      "Epoch 208/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 1.3089e-04 - accuracy: 1.0000 - val_loss: 1.0465 - val_accuracy: 0.8095\n",
      "Epoch 209/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 8.3912e-05 - accuracy: 1.0000 - val_loss: 1.0606 - val_accuracy: 0.8095\n",
      "Epoch 210/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 1.3212e-04 - accuracy: 1.0000 - val_loss: 1.1040 - val_accuracy: 0.7857\n",
      "Epoch 211/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 9.4887e-05 - accuracy: 1.0000 - val_loss: 1.1120 - val_accuracy: 0.8095\n",
      "Epoch 212/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 1.4703e-04 - accuracy: 1.0000 - val_loss: 1.0975 - val_accuracy: 0.8095\n",
      "Epoch 213/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 7.5451e-05 - accuracy: 1.0000 - val_loss: 1.0835 - val_accuracy: 0.7857\n",
      "Epoch 214/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 8.8921e-05 - accuracy: 1.0000 - val_loss: 1.0377 - val_accuracy: 0.8095\n",
      "Epoch 215/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 9.3241e-05 - accuracy: 1.0000 - val_loss: 1.0366 - val_accuracy: 0.8095\n",
      "Epoch 216/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 6.9255e-05 - accuracy: 1.0000 - val_loss: 1.0514 - val_accuracy: 0.8095\n",
      "Epoch 217/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 6.1632e-05 - accuracy: 1.0000 - val_loss: 1.0818 - val_accuracy: 0.7857\n",
      "Epoch 218/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 7.1683e-05 - accuracy: 1.0000 - val_loss: 1.0962 - val_accuracy: 0.7857\n",
      "Epoch 219/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 9.4517e-05 - accuracy: 1.0000 - val_loss: 1.0886 - val_accuracy: 0.7857\n",
      "Epoch 220/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 9.1265e-05 - accuracy: 1.0000 - val_loss: 1.0765 - val_accuracy: 0.8095\n",
      "Epoch 221/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 7.6443e-05 - accuracy: 1.0000 - val_loss: 1.0764 - val_accuracy: 0.8095\n",
      "Epoch 222/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 6.2478e-05 - accuracy: 1.0000 - val_loss: 1.0770 - val_accuracy: 0.8095\n",
      "Epoch 223/270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 2s 190ms/step - loss: 5.2455e-05 - accuracy: 1.0000 - val_loss: 1.0798 - val_accuracy: 0.8095\n",
      "Epoch 224/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 6.6894e-05 - accuracy: 1.0000 - val_loss: 1.0688 - val_accuracy: 0.8095\n",
      "Epoch 225/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 8.0252e-05 - accuracy: 1.0000 - val_loss: 1.0832 - val_accuracy: 0.8095\n",
      "Epoch 226/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 8.0970e-05 - accuracy: 1.0000 - val_loss: 1.1152 - val_accuracy: 0.7857\n",
      "Epoch 227/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 1.5035e-04 - accuracy: 1.0000 - val_loss: 1.0685 - val_accuracy: 0.8095\n",
      "Epoch 228/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 5.7025e-05 - accuracy: 1.0000 - val_loss: 1.0601 - val_accuracy: 0.8095\n",
      "Epoch 229/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 6.8696e-05 - accuracy: 1.0000 - val_loss: 1.0831 - val_accuracy: 0.8095\n",
      "Epoch 230/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 8.6616e-05 - accuracy: 1.0000 - val_loss: 1.1032 - val_accuracy: 0.8095\n",
      "Epoch 231/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 6.5469e-05 - accuracy: 1.0000 - val_loss: 1.1128 - val_accuracy: 0.8095\n",
      "Epoch 232/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 8.4445e-05 - accuracy: 1.0000 - val_loss: 1.1193 - val_accuracy: 0.8333\n",
      "Epoch 233/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 6.3119e-05 - accuracy: 1.0000 - val_loss: 1.1280 - val_accuracy: 0.8333\n",
      "Epoch 234/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 4.5147e-05 - accuracy: 1.0000 - val_loss: 1.1168 - val_accuracy: 0.8095\n",
      "Epoch 235/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 1.0299e-04 - accuracy: 1.0000 - val_loss: 1.1240 - val_accuracy: 0.8095\n",
      "Epoch 236/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 6.1465e-05 - accuracy: 1.0000 - val_loss: 1.1025 - val_accuracy: 0.8095\n",
      "Epoch 237/270\n",
      "12/12 [==============================] - 2s 188ms/step - loss: 8.3409e-05 - accuracy: 1.0000 - val_loss: 1.0631 - val_accuracy: 0.8095\n",
      "Epoch 238/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 5.0749e-05 - accuracy: 1.0000 - val_loss: 1.0657 - val_accuracy: 0.8095\n",
      "Epoch 239/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 8.4388e-05 - accuracy: 1.0000 - val_loss: 1.0700 - val_accuracy: 0.8095\n",
      "Epoch 240/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 6.5204e-05 - accuracy: 1.0000 - val_loss: 1.0719 - val_accuracy: 0.8333\n",
      "Epoch 241/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 6.2917e-05 - accuracy: 1.0000 - val_loss: 1.0699 - val_accuracy: 0.8095\n",
      "Epoch 242/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 5.1194e-05 - accuracy: 1.0000 - val_loss: 1.0723 - val_accuracy: 0.8095\n",
      "Epoch 243/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 1.1196e-04 - accuracy: 1.0000 - val_loss: 1.1065 - val_accuracy: 0.8095\n",
      "Epoch 244/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 7.7839e-05 - accuracy: 1.0000 - val_loss: 1.1387 - val_accuracy: 0.7857\n",
      "Epoch 245/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 4.7980e-05 - accuracy: 1.0000 - val_loss: 1.1320 - val_accuracy: 0.7857\n",
      "Epoch 246/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 4.2395e-05 - accuracy: 1.0000 - val_loss: 1.1142 - val_accuracy: 0.7857\n",
      "Epoch 247/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 5.3544e-05 - accuracy: 1.0000 - val_loss: 1.0939 - val_accuracy: 0.8095\n",
      "Epoch 248/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 5.6741e-05 - accuracy: 1.0000 - val_loss: 1.0800 - val_accuracy: 0.8333\n",
      "Epoch 249/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 7.6664e-05 - accuracy: 1.0000 - val_loss: 1.1040 - val_accuracy: 0.8333\n",
      "Epoch 250/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 1.7847e-04 - accuracy: 1.0000 - val_loss: 1.2111 - val_accuracy: 0.8095\n",
      "Epoch 251/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 6.5357e-05 - accuracy: 1.0000 - val_loss: 1.2554 - val_accuracy: 0.7857\n",
      "Epoch 252/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 9.8213e-05 - accuracy: 1.0000 - val_loss: 1.1494 - val_accuracy: 0.8333\n",
      "Epoch 253/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 6.8997e-05 - accuracy: 1.0000 - val_loss: 1.0789 - val_accuracy: 0.8333\n",
      "Epoch 254/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 8.9754e-05 - accuracy: 1.0000 - val_loss: 1.0676 - val_accuracy: 0.8333\n",
      "Epoch 255/270\n",
      "12/12 [==============================] - 2s 188ms/step - loss: 9.1129e-05 - accuracy: 1.0000 - val_loss: 1.1182 - val_accuracy: 0.7857\n",
      "Epoch 256/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 5.9943e-05 - accuracy: 1.0000 - val_loss: 1.1186 - val_accuracy: 0.7857\n",
      "Epoch 257/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 8.7722e-05 - accuracy: 1.0000 - val_loss: 1.0569 - val_accuracy: 0.8095\n",
      "Epoch 258/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 7.0353e-05 - accuracy: 1.0000 - val_loss: 1.0407 - val_accuracy: 0.8095\n",
      "Epoch 259/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 5.6347e-05 - accuracy: 1.0000 - val_loss: 1.0594 - val_accuracy: 0.7857\n",
      "Epoch 260/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 7.3118e-05 - accuracy: 1.0000 - val_loss: 1.0638 - val_accuracy: 0.7857\n",
      "Epoch 261/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 7.5225e-05 - accuracy: 1.0000 - val_loss: 1.0827 - val_accuracy: 0.8095\n",
      "Epoch 262/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 4.4966e-05 - accuracy: 1.0000 - val_loss: 1.0649 - val_accuracy: 0.8095\n",
      "Epoch 263/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 5.8640e-05 - accuracy: 1.0000 - val_loss: 1.0524 - val_accuracy: 0.8095\n",
      "Epoch 264/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 5.1679e-05 - accuracy: 1.0000 - val_loss: 1.0593 - val_accuracy: 0.8095\n",
      "Epoch 265/270\n",
      "12/12 [==============================] - 2s 191ms/step - loss: 4.6965e-05 - accuracy: 1.0000 - val_loss: 1.0678 - val_accuracy: 0.8095\n",
      "Epoch 266/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 5.6980e-05 - accuracy: 1.0000 - val_loss: 1.0818 - val_accuracy: 0.8095\n",
      "Epoch 267/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 3.7729e-05 - accuracy: 1.0000 - val_loss: 1.0921 - val_accuracy: 0.8095\n",
      "Epoch 268/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 4.4635e-05 - accuracy: 1.0000 - val_loss: 1.0939 - val_accuracy: 0.8095\n",
      "Epoch 269/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 3.5167e-05 - accuracy: 1.0000 - val_loss: 1.0975 - val_accuracy: 0.8095\n",
      "Epoch 270/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 4.5474e-05 - accuracy: 1.0000 - val_loss: 1.0815 - val_accuracy: 0.8095\n"
     ]
    }
   ],
   "source": [
    "epochs =270\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset, \n",
    "    epochs=epochs,\n",
    "    validation_data=test_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile model\n",
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss='mse',\n",
    "  metrics=[tf.keras.metrics.CategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0589 - categorical_accuracy: 0.8095\n",
      "Test Accuracy: 80.95%\n"
     ]
    }
   ],
   "source": [
    "evaluation = model.evaluate(test_dataset)\n",
    "print(f\"Test Accuracy: {evaluation[1] * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 - 0s - loss: 0.0589 - categorical_accuracy: 0.8095 - 110ms/epoch - 55ms/step\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_dataset, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 - 0s - loss: 1.0815 - accuracy: 0.8095 - 367ms/epoch - 183ms/step\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_dataset, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 1s 41ms/step - loss: 1.0026e-05 - accuracy: 1.0000\n",
      "Train Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "evaluation = model.evaluate(train_dataset)\n",
    "print(f\"Train Accuracy: {evaluation[1] * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A Not Ripe', 'A Ripe', 'B Not Ripe', 'B Ripe', 'C Not Ripe', 'C Ripe']\n"
     ]
    }
   ],
   "source": [
    "class_names = test_dataset.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to A Ripe with a 35.22 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#1 A Ripe\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/A Ripe/AR10_90.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to A Ripe with a 35.11 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#2\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/A Ripe/AR11_180.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to A Ripe with a 35.22 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#3\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/A Ripe/AR12_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to A Not Ripe with a 34.09 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#4\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/A Ripe/AR13_180.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to A Ripe with a 35.22 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#5\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/A Ripe/AR14_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to A Ripe with a 35.22 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#6\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/A Ripe/AR15_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to A Ripe with a 35.22 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#7\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/A Ripe/AR16_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to A Ripe with a 28.74 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#8\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/A Ripe/AR1_270.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160,160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to A Ripe with a 35.22 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#9\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/A Ripe/AR2_180.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160,160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to A Ripe with a 35.22 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#10\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/A Ripe/AR3_180.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160,160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to A Ripe with a 34.99 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#11\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/A Ripe/AR4_270.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160,160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to A Ripe with a 35.21 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#12\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/A Ripe/AR5_180.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to A Ripe with a 35.21 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#13\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/A Ripe/AR6_270.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to A Ripe with a 24.16 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#14\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/A Ripe/AR77_270.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to A Ripe with a 34.30 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#15\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/A Ripe/AR78_90.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to A Ripe with a 35.22 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#17\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/A Ripe/AR7_180.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to A Ripe with a 35.22 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#17\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/A Ripe/AR7_180.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to A Ripe with a 35.22 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#18\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/A Ripe/AR8_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to A Ripe with a 35.22 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#19\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/A Ripe/AR9_270.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to A Not Ripe with a 35.22 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#1 A Not Ripe\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/A Not Ripe/ANR10_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to A Not Ripe with a 35.22 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#2\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/A Not Ripe/ANR11_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to A Not Ripe with a 35.22 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#3\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/A Not Ripe/ANR12_90.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to A Not Ripe with a 35.12 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#4\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/A Not Ripe/ANR13_90.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160,160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to A Not Ripe with a 35.22 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#5\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/A Not Ripe/ANR14_180.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160,160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to A Not Ripe with a 35.22 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#6\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/A Not Ripe/ANR15_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to A Not Ripe with a 35.22 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#7\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/A Not Ripe/ANR16_90.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to A Not Ripe with a 35.22 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#8\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/A Not Ripe/ANR1_270.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to A Not Ripe with a 35.22 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#9\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/A Not Ripe/ANR2_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to A Not Ripe with a 35.22 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#10\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/A Not Ripe/ANR3_270.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to A Not Ripe with a 35.22 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#11\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/A Not Ripe/ANR4_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to A Not Ripe with a 35.20 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#12\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/A Not Ripe/ANR5_90.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to A Not Ripe with a 35.22 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#13\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/A Not Ripe/ANR6_270.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to A Not Ripe with a 35.21 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#14\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/A Not Ripe/ANR79_270.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to A Not Ripe with a 35.22 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#15\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/A Not Ripe/ANR7_90.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to A Not Ripe with a 35.22 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#16\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/A Not Ripe/ANR80_90.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to A Not Ripe with a 35.22 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#17\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/A Not Ripe/ANR81_90.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to A Not Ripe with a 35.22 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#18\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/A Not Ripe/ANR8_90.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to A Not Ripe with a 35.22 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#19\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/A Not Ripe/ANR9_270.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to A Ripe with a 34.48 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#1 B Ripe\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/B Ripe/BR10_180.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to C Ripe with a 26.24 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#2\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/B Ripe/BR11_90.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to B Ripe with a 34.87 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#3\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/B Ripe/BR12_180.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to A Ripe with a 33.42 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#4\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/B Ripe/BR13_90.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to B Ripe with a 33.97 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#5\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/B Ripe/BR14_180.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to B Ripe with a 33.85 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#6\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/B Ripe/BR15_180.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to C Not Ripe with a 34.66 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#7\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/B Ripe/BR16_270.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to C Not Ripe with a 34.81 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#8\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/B Ripe/BR1_90.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to C Not Ripe with a 20.79 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#9\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/B Ripe/BR2_270.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to C Ripe with a 24.84 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#10\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/B Ripe/BR3_90.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to B Ripe with a 34.28 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#11\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/B Ripe/BR4_180.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to B Ripe with a 33.27 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#12\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/B Ripe/BR5_180.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to B Ripe with a 35.22 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#13\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/B Ripe/BR65_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to A Ripe with a 31.98 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#14\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/B Ripe/BR66_270.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to B Ripe with a 35.11 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#15\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/B Ripe/BR67_270.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to B Ripe with a 28.95 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#16\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/B Ripe/BR6_90.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to A Ripe with a 20.52 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#17\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/B Ripe/BR7_90.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to A Not Ripe with a 26.50 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#18\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/B Ripe/BR8_180.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to A Ripe with a 33.68 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#19\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/B Ripe/BR9_180.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to B Not Ripe with a 35.22 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#1 B Not Ripe\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/B Not Ripe/BNR10_270.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to B Not Ripe with a 26.10 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#2\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/B Not Ripe/BNR11_270.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to C Not Ripe with a 26.29 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#3\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/B Not Ripe/BNR12_270.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to B Ripe with a 34.41 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#4\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/B Not Ripe/BNR13_180.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to B Not Ripe with a 35.22 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#5\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/B Not Ripe/BNR14_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to B Not Ripe with a 24.66 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#6\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/B Not Ripe/BNR15_90.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to B Ripe with a 34.07 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#7\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/B Not Ripe/BNR16_270.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to B Not Ripe with a 35.22 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#8\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/B Not Ripe/BNR1_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to B Not Ripe with a 35.22 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#9\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/B Not Ripe/BNR2_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to C Ripe with a 23.68 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#10\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/B Not Ripe/BNR3_270.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to B Not Ripe with a 35.22 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#11\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/B Not Ripe/BNR4_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to B Ripe with a 31.65 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#12\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/B Not Ripe/BNR5_90.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to C Ripe with a 27.98 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#13\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/B Not Ripe/BNR69_180.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to C Not Ripe with a 35.20 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#14\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/B Not Ripe/BNR6_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to C Not Ripe with a 28.56 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#15\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/B Not Ripe/BNR70_180.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to B Not Ripe with a 35.20 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#16\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/B Not Ripe/BNR71_270.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to B Not Ripe with a 35.22 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#17\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/B Not Ripe/BNR7_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to B Not Ripe with a 27.31 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#18\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/B Not Ripe/BNR8_180.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to C Ripe with a 34.82 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#19\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/B Not Ripe/BNR9_90.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to C Ripe with a 35.22 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#1 C Ripe\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/C Ripe/CR11_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to C Ripe with a 35.16 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#2\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/C Ripe/CR13_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to C Ripe with a 35.22 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#3\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/C Ripe/CR22_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to C Ripe with a 35.22 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#4\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/C Ripe/CR24_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to C Ripe with a 35.22 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#5\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/C Ripe/CR30_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to C Ripe with a 35.22 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#6\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/C Ripe/CR32_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to C Ripe with a 35.22 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#7\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/C Ripe/CR38_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to C Ripe with a 35.22 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#8\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/C Ripe/CR44_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to C Ripe with a 35.22 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#9\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/C Ripe/CR45_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to C Ripe with a 35.22 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#10\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/C Ripe/CR46_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to C Ripe with a 35.22 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#11\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/C Ripe/CR47_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to C Ripe with a 35.22 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#12\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/C Ripe/CR4_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to C Ripe with a 35.22 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#13\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/C Ripe/CR50_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to C Ripe with a 35.22 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#14\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/C Ripe/CR51_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to C Ripe with a 35.22 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#15\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/C Ripe/CR60_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to C Ripe with a 35.22 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#16\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/C Ripe/CR62_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to C Ripe with a 35.22 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#17\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/C Ripe/CR63_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to C Ripe with a 35.22 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#18\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/C Ripe/CR64_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to C Ripe with a 35.22 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#19\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/C Ripe/CR8_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to C Not Ripe with a 35.22 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#1 C Not Ripe\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/C Not Ripe/CNR10_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to C Not Ripe with a 35.22 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#2\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/C Not Ripe/CNR11_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to C Not Ripe with a 35.22 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#3\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/C Not Ripe/CNR1_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to C Not Ripe with a 35.22 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#4\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/C Not Ripe/CNR20_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to C Not Ripe with a 35.22 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#5\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/C Not Ripe/CNR22_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to C Not Ripe with a 35.22 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#6\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/C Not Ripe/CNR28_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to C Not Ripe with a 35.22 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#7\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/C Not Ripe/CNR30_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to C Not Ripe with a 35.22 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#8\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/C Not Ripe/CNR38_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to C Not Ripe with a 34.97 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#9\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/C Not Ripe/CNR43_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to C Not Ripe with a 35.22 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#10\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/C Not Ripe/CNR52_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to C Not Ripe with a 35.22 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#11\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/C Not Ripe/CNR57_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to C Not Ripe with a 35.22 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#12\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/C Not Ripe/CNR58_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to C Not Ripe with a 35.22 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#13\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/C Not Ripe/CNR59_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to C Not Ripe with a 35.22 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#14\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/C Not Ripe/CNR5_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to C Not Ripe with a 35.22 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#15\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/C Not Ripe/CNR62_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to C Not Ripe with a 35.22 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#16\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/C Not Ripe/CNR63_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to C Not Ripe with a 35.22 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#17\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/C Not Ripe/CNR64_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to C Ripe with a 35.22 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#18\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/C Not Ripe/CNR6_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to C Ripe with a 34.42 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#19\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/C Not Ripe/CNR9_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training')\n",
    "plt.plot(epochs_range, val_acc, label='Test')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training')\n",
    "plt.plot(epochs_range, val_loss, label='Test')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Loss')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
