{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import preprocessing\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Activation,BatchNormalization, Dropout\n",
    "from tensorflow.keras import Sequential\n",
    "from keras.optimizers import *\n",
    "\"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import PIL\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 426 files belonging to 6 classes.\n",
      "Using 384 files for training.\n"
     ]
    }
   ],
   "source": [
    "#load train images\n",
    "img_size=160\n",
    "train_dataset = tf.keras.utils.image_dataset_from_directory('C:/Users/User/Documents/UPM/Semester 3/Category/basedata',\n",
    "                                                            validation_split=0.1,\n",
    "                                                            batch_size = 32,\n",
    "                                                            label_mode = 'categorical',\n",
    "                                                            subset='training',\n",
    "                                                            seed=123,\n",
    "                                                            image_size=(img_size,img_size),\n",
    "                                                            shuffle=True\n",
    "                                                           )\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 426 files belonging to 6 classes.\n",
      "Using 42 files for validation.\n"
     ]
    }
   ],
   "source": [
    "#load test images\n",
    "img_size=160\n",
    "test_dataset = tf.keras.utils.image_dataset_from_directory('C:/Users/User/Documents/UPM/Semester 3/Category/basedata',\n",
    "                                                           validation_split=0.1,\n",
    "                                                           batch_size = 32,\n",
    "                                                           label_mode = 'categorical',\n",
    "                                                           subset='validation',\n",
    "                                                           seed=123,\n",
    "                                                           image_size=(img_size,img_size),\n",
    "                                                           shuffle=True\n",
    "                                                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_layer = tf.keras.layers.Rescaling(1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 150, 150, 64)      23296     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 75, 75, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 75, 75, 64)       256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 65, 65, 128)       991360    \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 32, 32, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 32, 32, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 22, 22, 256)       3965184   \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 11, 11, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 11, 11, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " global_max_pooling2d (Globa  (None, 256)              0         \n",
      " lMaxPooling2D)                                                  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               65792     \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 6)                 1542      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,049,990\n",
      "Trainable params: 5,048,582\n",
      "Non-trainable params: 1,408\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "img_size=160\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "# Input layer\n",
    "# Can be omitted, you can specify the input_shape in other layers\n",
    "model.add(tf.keras.layers.InputLayer(input_shape=(img_size,img_size,3)))\n",
    "\n",
    "# 1st 2D Convolution layer\n",
    "model.add(tf.keras.layers.Conv2D(64, kernel_size=(11,11), activation='relu'))\n",
    "# Max Pool layer \n",
    "# It downsmaples the input representetion within the pool_size size\n",
    "model.add(tf.keras.layers.MaxPool2D())\n",
    "# Normalization layer\n",
    "# The layer normalizes its output using the mean and standard deviation of the current batch of inputs.\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "\n",
    "# 2nd 2D Convolution layer\n",
    "model.add(tf.keras.layers.Conv2D(128, kernel_size=(11,11),activation='relu'))\n",
    "# Max Pool layer \n",
    "model.add(tf.keras.layers.MaxPool2D())\n",
    "# Normalization layer\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "# 1st fully convolutional layer \n",
    "model.add(tf.keras.layers.Conv2D(256, kernel_size=(11,11),activation='relu'))\n",
    "# Max Pool layer \n",
    "model.add(tf.keras.layers.MaxPool2D())\n",
    "# Normalization layer\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "# Global Max Pool layer\n",
    "model.add(tf.keras.layers.GlobalMaxPool2D())\n",
    "\n",
    "\n",
    "# Dense Layers after flattening the data\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "\n",
    "# Normalization layer\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "#Add Output Layer\n",
    "model.add(tf.keras.layers.Dense(6, activation='softmax')) # = 12 predicted classes\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "#custom_early_stopping = EarlyStopping(\n",
    "#    monitor='val_accuracy', \n",
    "#    patience=20, \n",
    "#    min_delta=0.001, \n",
    "#    mode='max'\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/270\n",
      "12/12 [==============================] - 17s 597ms/step - loss: 1.4222 - accuracy: 0.4375 - val_loss: 1010.6949 - val_accuracy: 0.1667\n",
      "Epoch 2/270\n",
      "12/12 [==============================] - 2s 188ms/step - loss: 0.8650 - accuracy: 0.6797 - val_loss: 461.4585 - val_accuracy: 0.1667\n",
      "Epoch 3/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 0.6120 - accuracy: 0.7656 - val_loss: 259.5334 - val_accuracy: 0.1667\n",
      "Epoch 4/270\n",
      "12/12 [==============================] - 2s 191ms/step - loss: 0.4986 - accuracy: 0.8073 - val_loss: 169.2014 - val_accuracy: 0.1667\n",
      "Epoch 5/270\n",
      "12/12 [==============================] - 2s 195ms/step - loss: 0.4312 - accuracy: 0.8542 - val_loss: 129.8732 - val_accuracy: 0.1667\n",
      "Epoch 6/270\n",
      "12/12 [==============================] - 3s 205ms/step - loss: 0.3642 - accuracy: 0.8750 - val_loss: 88.5362 - val_accuracy: 0.1667\n",
      "Epoch 7/270\n",
      "12/12 [==============================] - 3s 203ms/step - loss: 0.3299 - accuracy: 0.8724 - val_loss: 59.9320 - val_accuracy: 0.1667\n",
      "Epoch 8/270\n",
      "12/12 [==============================] - 2s 193ms/step - loss: 0.2879 - accuracy: 0.9141 - val_loss: 36.5261 - val_accuracy: 0.1667\n",
      "Epoch 9/270\n",
      "12/12 [==============================] - 3s 200ms/step - loss: 0.2174 - accuracy: 0.9453 - val_loss: 39.9385 - val_accuracy: 0.1667\n",
      "Epoch 10/270\n",
      "12/12 [==============================] - 2s 192ms/step - loss: 0.1703 - accuracy: 0.9505 - val_loss: 31.7988 - val_accuracy: 0.1667\n",
      "Epoch 11/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 0.1762 - accuracy: 0.9505 - val_loss: 24.4920 - val_accuracy: 0.1667\n",
      "Epoch 12/270\n",
      "12/12 [==============================] - 3s 197ms/step - loss: 0.2012 - accuracy: 0.9349 - val_loss: 22.4021 - val_accuracy: 0.1667\n",
      "Epoch 13/270\n",
      "12/12 [==============================] - 3s 196ms/step - loss: 0.2125 - accuracy: 0.9427 - val_loss: 17.8934 - val_accuracy: 0.1667\n",
      "Epoch 14/270\n",
      "12/12 [==============================] - 3s 197ms/step - loss: 0.2038 - accuracy: 0.9245 - val_loss: 14.4170 - val_accuracy: 0.2381\n",
      "Epoch 15/270\n",
      "12/12 [==============================] - 3s 204ms/step - loss: 0.2089 - accuracy: 0.9297 - val_loss: 16.1574 - val_accuracy: 0.1667\n",
      "Epoch 16/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 0.1557 - accuracy: 0.9479 - val_loss: 11.3420 - val_accuracy: 0.1667\n",
      "Epoch 17/270\n",
      "12/12 [==============================] - 2s 192ms/step - loss: 0.1017 - accuracy: 0.9922 - val_loss: 5.9070 - val_accuracy: 0.2857\n",
      "Epoch 18/270\n",
      "12/12 [==============================] - 2s 188ms/step - loss: 0.0974 - accuracy: 0.9740 - val_loss: 4.7697 - val_accuracy: 0.3810\n",
      "Epoch 19/270\n",
      "12/12 [==============================] - 2s 193ms/step - loss: 0.0703 - accuracy: 0.9896 - val_loss: 2.9406 - val_accuracy: 0.4286\n",
      "Epoch 20/270\n",
      "12/12 [==============================] - 2s 196ms/step - loss: 0.0414 - accuracy: 0.9974 - val_loss: 2.3200 - val_accuracy: 0.6667\n",
      "Epoch 21/270\n",
      "12/12 [==============================] - 3s 192ms/step - loss: 0.0301 - accuracy: 1.0000 - val_loss: 0.8476 - val_accuracy: 0.6905\n",
      "Epoch 22/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 0.0233 - accuracy: 0.9974 - val_loss: 1.0408 - val_accuracy: 0.7143\n",
      "Epoch 23/270\n",
      "12/12 [==============================] - 3s 197ms/step - loss: 0.0184 - accuracy: 0.9974 - val_loss: 1.5592 - val_accuracy: 0.6667\n",
      "Epoch 24/270\n",
      "12/12 [==============================] - 3s 189ms/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 1.2341 - val_accuracy: 0.7381\n",
      "Epoch 25/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.9570 - val_accuracy: 0.7143\n",
      "Epoch 26/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 1.0180 - val_accuracy: 0.7143\n",
      "Epoch 27/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.9217 - val_accuracy: 0.7143\n",
      "Epoch 28/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.8974 - val_accuracy: 0.7143\n",
      "Epoch 29/270\n",
      "12/12 [==============================] - 2s 192ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.9374 - val_accuracy: 0.6905\n",
      "Epoch 30/270\n",
      "12/12 [==============================] - 3s 191ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.0282 - val_accuracy: 0.6667\n",
      "Epoch 31/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.9608 - val_accuracy: 0.6905\n",
      "Epoch 32/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.8974 - val_accuracy: 0.7619\n",
      "Epoch 33/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.9215 - val_accuracy: 0.7857\n",
      "Epoch 34/270\n",
      "12/12 [==============================] - 2s 191ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.9481 - val_accuracy: 0.7619\n",
      "Epoch 35/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.0095 - val_accuracy: 0.7381\n",
      "Epoch 36/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.1250 - val_accuracy: 0.7619\n",
      "Epoch 37/270\n",
      "12/12 [==============================] - 2s 191ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.2098 - val_accuracy: 0.7619\n",
      "Epoch 38/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.0942 - val_accuracy: 0.7619\n",
      "Epoch 39/270\n",
      "12/12 [==============================] - 2s 192ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.1310 - val_accuracy: 0.7619\n",
      "Epoch 40/270\n",
      "12/12 [==============================] - 3s 194ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.0819 - val_accuracy: 0.7143\n",
      "Epoch 41/270\n",
      "12/12 [==============================] - 3s 190ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.1320 - val_accuracy: 0.7381\n",
      "Epoch 42/270\n",
      "12/12 [==============================] - 2s 191ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.1286 - val_accuracy: 0.7381\n",
      "Epoch 43/270\n",
      "12/12 [==============================] - 3s 193ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.1222 - val_accuracy: 0.7381\n",
      "Epoch 44/270\n",
      "12/12 [==============================] - 2s 194ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.2534 - val_accuracy: 0.7381\n",
      "Epoch 45/270\n",
      "12/12 [==============================] - 3s 202ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.2482 - val_accuracy: 0.7381\n",
      "Epoch 46/270\n",
      "12/12 [==============================] - 2s 191ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.2159 - val_accuracy: 0.7619\n",
      "Epoch 47/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.2684 - val_accuracy: 0.7381\n",
      "Epoch 48/270\n",
      "12/12 [==============================] - 2s 191ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.2782 - val_accuracy: 0.7619\n",
      "Epoch 49/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.2642 - val_accuracy: 0.7381\n",
      "Epoch 50/270\n",
      "12/12 [==============================] - 2s 191ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.1587 - val_accuracy: 0.7619\n",
      "Epoch 51/270\n",
      "12/12 [==============================] - 2s 192ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.2366 - val_accuracy: 0.7143\n",
      "Epoch 52/270\n",
      "12/12 [==============================] - 2s 189ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.1601 - val_accuracy: 0.7381\n",
      "Epoch 53/270\n",
      "12/12 [==============================] - 2s 191ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.1708 - val_accuracy: 0.7619\n",
      "Epoch 54/270\n",
      "12/12 [==============================] - 2s 190ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.2099 - val_accuracy: 0.7381\n",
      "Epoch 55/270\n",
      "12/12 [==============================] - 2s 191ms/step - loss: 8.8041e-04 - accuracy: 1.0000 - val_loss: 1.1686 - val_accuracy: 0.7381\n",
      "Epoch 56/270\n",
      "12/12 [==============================] - 3s 195ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.1597 - val_accuracy: 0.7619\n",
      "Epoch 57/270\n",
      "12/12 [==============================] - 3s 200ms/step - loss: 9.7258e-04 - accuracy: 1.0000 - val_loss: 1.1928 - val_accuracy: 0.7619\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/270\n",
      "12/12 [==============================] - 3s 201ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.1840 - val_accuracy: 0.7619\n",
      "Epoch 59/270\n",
      "12/12 [==============================] - 3s 208ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.1833 - val_accuracy: 0.7619\n",
      "Epoch 60/270\n",
      "12/12 [==============================] - 3s 192ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.1762 - val_accuracy: 0.7381\n",
      "Epoch 61/270\n",
      "12/12 [==============================] - 3s 196ms/step - loss: 7.5905e-04 - accuracy: 1.0000 - val_loss: 1.1525 - val_accuracy: 0.7619\n",
      "Epoch 62/270\n",
      "12/12 [==============================] - 3s 206ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.1500 - val_accuracy: 0.7381\n",
      "Epoch 63/270\n",
      "12/12 [==============================] - 3s 206ms/step - loss: 6.4764e-04 - accuracy: 1.0000 - val_loss: 1.1667 - val_accuracy: 0.7619\n",
      "Epoch 64/270\n",
      "12/12 [==============================] - 3s 198ms/step - loss: 9.6698e-04 - accuracy: 1.0000 - val_loss: 1.2332 - val_accuracy: 0.7857\n",
      "Epoch 65/270\n",
      "12/12 [==============================] - 2s 194ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.2681 - val_accuracy: 0.7619\n",
      "Epoch 66/270\n",
      "12/12 [==============================] - 2s 193ms/step - loss: 7.9806e-04 - accuracy: 1.0000 - val_loss: 1.3044 - val_accuracy: 0.7857\n",
      "Epoch 67/270\n",
      "12/12 [==============================] - 3s 197ms/step - loss: 7.6760e-04 - accuracy: 1.0000 - val_loss: 1.2819 - val_accuracy: 0.7619\n",
      "Epoch 68/270\n",
      " 3/12 [======>.......................] - ETA: 1s - loss: 4.2467e-04 - accuracy: 1.0000"
     ]
    }
   ],
   "source": [
    "epochs =270\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset, \n",
    "    epochs=epochs,\n",
    "    validation_data=test_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile model\n",
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss='mse',\n",
    "  metrics=[tf.keras.metrics.CategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = model.evaluate(test_dataset)\n",
    "print(f\"Test Accuracy: {evaluation[1] * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_dataset, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_dataset, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = model.evaluate(train_dataset)\n",
    "print(f\"Train Accuracy: {evaluation[1] * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = test_dataset.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 A Ripe\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/A Ripe/AR10_90.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/A Ripe/AR11_180.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/A Ripe/AR12_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/A Ripe/AR13_180.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/A Ripe/AR14_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/A Ripe/AR15_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/A Ripe/AR16_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#8\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/A Ripe/AR1_270.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160,160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#9\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/A Ripe/AR2_180.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160,160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#10\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/A Ripe/AR3_180.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160,160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#11\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/A Ripe/AR4_270.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160,160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#12\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/A Ripe/AR5_180.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#13\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/A Ripe/AR6_270.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#14\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/A Ripe/AR77_270.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#15\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/A Ripe/AR78_90.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#17\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/A Ripe/AR7_180.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#17\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/A Ripe/AR7_180.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#18\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/A Ripe/AR8_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#19\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/A Ripe/AR9_270.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 A Not Ripe\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/A Not Ripe/ANR10_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/A Not Ripe/ANR11_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/A Not Ripe/ANR12_90.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/A Not Ripe/ANR13_90.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160,160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/A Not Ripe/ANR14_180.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160,160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/A Not Ripe/ANR15_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/A Not Ripe/ANR16_90.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#8\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/A Not Ripe/ANR1_270.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#9\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/A Not Ripe/ANR2_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#10\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/A Not Ripe/ANR3_270.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#11\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/A Not Ripe/ANR4_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#12\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/A Not Ripe/ANR5_90.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#13\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/A Not Ripe/ANR6_270.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#14\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/A Not Ripe/ANR79_270.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#15\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/A Not Ripe/ANR7_90.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#16\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/A Not Ripe/ANR80_90.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#17\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/A Not Ripe/ANR81_90.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#18\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/A Not Ripe/ANR8_90.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#19\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/A Not Ripe/ANR9_270.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 B Ripe\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/B Ripe/BR10_180.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/B Ripe/BR11_90.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/B Ripe/BR12_180.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/B Ripe/BR13_90.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/B Ripe/BR14_180.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/B Ripe/BR15_180.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/B Ripe/BR16_270.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#8\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/B Ripe/BR1_90.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#9\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/B Ripe/BR2_270.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#10\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/B Ripe/BR3_90.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#11\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/B Ripe/BR4_180.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#12\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/B Ripe/BR5_180.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#13\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/B Ripe/BR65_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#14\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/B Ripe/BR66_270.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#15\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/B Ripe/BR67_270.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#16\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/B Ripe/BR6_90.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#17\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/B Ripe/BR7_90.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#18\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/B Ripe/BR8_180.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#19\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/B Ripe/BR9_180.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 B Not Ripe\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/B Not Ripe/BNR10_270.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/B Not Ripe/BNR11_270.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/B Not Ripe/BNR12_270.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/B Not Ripe/BNR13_180.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/B Not Ripe/BNR14_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/B Not Ripe/BNR15_90.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/B Not Ripe/BNR16_270.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#8\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/B Not Ripe/BNR1_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#9\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/B Not Ripe/BNR2_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#10\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/B Not Ripe/BNR3_270.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#11\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/B Not Ripe/BNR4_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#12\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/B Not Ripe/BNR5_90.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#13\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/B Not Ripe/BNR69_180.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#14\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/B Not Ripe/BNR6_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#15\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/B Not Ripe/BNR70_180.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#16\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/B Not Ripe/BNR71_270.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#17\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/B Not Ripe/BNR7_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#18\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/B Not Ripe/BNR8_180.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#19\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/B Not Ripe/BNR9_90.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 C Ripe\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/C Ripe/CR11_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/C Ripe/CR13_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/C Ripe/CR22_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/C Ripe/CR24_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/C Ripe/CR30_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/C Ripe/CR32_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/C Ripe/CR38_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#8\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/C Ripe/CR44_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#9\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/C Ripe/CR45_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#10\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/C Ripe/CR46_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#11\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/C Ripe/CR47_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#12\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/C Ripe/CR4_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#13\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/C Ripe/CR50_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#14\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/C Ripe/CR51_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#15\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/C Ripe/CR60_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#16\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/C Ripe/CR62_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#17\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/C Ripe/CR63_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#18\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/C Ripe/CR64_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#19\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/C Ripe/CR8_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 C Not Ripe\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/C Not Ripe/CNR10_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/C Not Ripe/CNR11_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/C Not Ripe/CNR1_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/C Not Ripe/CNR20_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/C Not Ripe/CNR22_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/C Not Ripe/CNR28_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/C Not Ripe/CNR30_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#8\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/C Not Ripe/CNR38_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#9\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/C Not Ripe/CNR43_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#10\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/C Not Ripe/CNR52_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#11\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/C Not Ripe/CNR57_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#12\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/C Not Ripe/CNR58_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#13\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/C Not Ripe/CNR59_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#14\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/C Not Ripe/CNR5_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#15\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/C Not Ripe/CNR62_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#16\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/C Not Ripe/CNR63_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#17\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/C Not Ripe/CNR64_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#18\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/C Not Ripe/CNR6_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#19\n",
    "\n",
    "rootdir = \"C:/Users/User/Desktop/Category/test/C Not Ripe/CNR9_0.png\"\n",
    "img = tf.keras.utils.load_img(\n",
    "    rootdir, target_size=(160, 160)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, axis=0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training')\n",
    "plt.plot(epochs_range, val_acc, label='Test')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training')\n",
    "plt.plot(epochs_range, val_loss, label='Test')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Loss')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
